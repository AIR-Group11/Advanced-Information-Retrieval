{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVnH1uZ2NvdR"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install sentence-transformers\n",
    "!pip install transformers\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install pinecone\n",
    "!pip install pinecone-client\n",
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736617333174,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "7KMfYxvoOAUJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import csv\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736617333175,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "Cng6SewPXDQP"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'api_key'\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1736617333578,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "mhea4Xep6e6C",
    "outputId": "872c2019-010c-411c-b24d-453c98d91931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone setup complete!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec, Index\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=\"api_key\")\n",
    "\n",
    "index_name = \"air\"\n",
    "\n",
    "# Check if the index exists; create it if it doesn't\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,  # Dimension of your embeddings\n",
    "        metric=\"cosine\",  # Similarity metric\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "print(\"Pinecone setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736617333578,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "naPFLP-SNvdc"
   },
   "outputs": [],
   "source": [
    "def load_lyrics_dataset(file_path):\n",
    "    try:\n",
    "        # Attempt to read the file with 'latin1' encoding\n",
    "        df = pd.read_csv(file_path, encoding='latin1', on_bad_lines='skip')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Preprocessing\n",
    "    # Remove rows with missing values in key columns\n",
    "    df = df.dropna(subset=['Artist', 'Song', 'Lyrics'])\n",
    "    # Remove rows where lyrics have fewer than 3 words\n",
    "    df['lyrics_word_count'] = df['Lyrics'].apply(lambda x: len(str(x).split()))\n",
    "    df = df[df['lyrics_word_count'] >= 3]\n",
    "\n",
    "    df = df.drop(columns=['lyrics_word_count'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736617333578,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "E8FpEOKZN-lI"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_lyrics(lyrics, chunk_size=100, overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=overlap\n",
    "    )\n",
    "    return splitter.split_text(lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736617333578,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "Kbip6bwfFTVq"
   },
   "outputs": [],
   "source": [
    "def preprocess_and_store_embeddings(data, index, chunk_size=100, overlap=50, batch_size=100):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    bi_encoder = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    rows = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        lyrics = row['Lyrics']\n",
    "        Song = row['Song']\n",
    "        artist = row['Artist']\n",
    "\n",
    "        # Convert lyrics to string and handle potential NaN values\n",
    "        lyrics = str(lyrics)  # Ensure lyrics is a string\n",
    "        if lyrics.lower() == 'nan':\n",
    "            continue\n",
    "\n",
    "        # Use LangChain chunker\n",
    "        chunks = splitter.split_text(lyrics)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            rows.append((f\"{idx}-{i}\", chunk, Song, artist))\n",
    "\n",
    "    for i in range(0, len(rows), batch_size):\n",
    "        batch = rows[i:i+batch_size]\n",
    "\n",
    "        # Extract chunks for embedding\n",
    "        chunks = [row[1] for row in batch]\n",
    "        embeddings = bi_encoder.encode(chunks, convert_to_tensor=False)\n",
    "\n",
    "        # Prepare data for upsert\n",
    "        vectors = []\n",
    "        for (vector_id, chunk, Song, artist), embedding in zip(batch, embeddings):\n",
    "            metadata = {\n",
    "                \"Song\": Song,\n",
    "                \"Artist\": artist,\n",
    "                \"Lyrics\": chunk\n",
    "            }\n",
    "            vectors.append((vector_id, embedding.tolist(), metadata))\n",
    "\n",
    "        # Upsert the batch to Pinecone\n",
    "        index.upsert(vectors)\n",
    "        print(f\"Upserted batch {i//batch_size + 1}/{(len(rows) + batch_size - 1) // batch_size}\")\n",
    "\n",
    "    print(\"Embeddings stored in Pinecone!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736617333579,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "UPR7hHV0Nvde"
   },
   "outputs": [],
   "source": [
    "class BiEncoder:\n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def encode_texts(self, texts):\n",
    "        \"\"\"Used for encoding lyrics into embeddings.\"\"\"\n",
    "        return self.model.encode(texts, convert_to_tensor=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736617333579,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "UbcthLP0WCjj"
   },
   "outputs": [],
   "source": [
    "def refine_query_with_chatgpt(query):\n",
    "    # Few-shot examples to guide the model\n",
    "    example_message = (\n",
    "        \"You are a helpful assistant tasked with extracting and correcting song lyrics \"\n",
    "        \"from user input and identifying the author if mentioned. You should return only the \"\n",
    "        \"lyric portion of the query and refine it for correctness. Format your output as follows:\\n\"\n",
    "        \"query: <start_query>original_query<end_query>\\n\"\n",
    "        \"refined_query: <start_refined_query>refined_lyric<end_refined_query>\\n\"\n",
    "        \"author: <start_author>author_name<end_author>\\n\"\n",
    "        \"If the author is not mentioned, return 'NOT_MENTIONED' for the author.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"1. User input: \\\"What's the song from Rihanna that goes like 'how about a round of applause'\\\"\\n\"\n",
    "        \"   Output:\\n\"\n",
    "        \"   query: <start_query>how about a round of applause<end_query>\\n\"\n",
    "        \"   refined_query: <start_refined_query>How about a round of applause<end_refined_query>\\n\"\n",
    "        \"   author: <start_author>Rihanna<end_author>\\n\\n\"\n",
    "        \"2. User input: \\\"Twinkle twinkle litl star how I wondr wht u ar\\\"\\n\"\n",
    "        \"   Output:\\n\"\n",
    "        \"   query: <start_query>Twinkle twinkle litl star how I wondr wht u ar<end_query>\\n\"\n",
    "        \"   refined_query: <start_refined_query>Twinkle twinkle little star how I wonder what you are<end_refined_query>\\n\"\n",
    "        \"   author: <start_author>NOT_MENTIONED<end_author>\\n\\n\"\n",
    "        \"3. User input: \\\"song about a broken heart\\\"\\n\"\n",
    "        \"   Output:\\n\"\n",
    "        \"   query: <start_query>a broken heart<end_query>\\n\"\n",
    "        \"   refined_query: <start_refined_query>A broken heart<end_refined_query>\\n\"\n",
    "        \"   author: <start_author>NOT_MENTIONED<end_author>\\n\\n\"\n",
    "        \"Now process this input:\\n\"\n",
    "        f\"User input: {query}\"\n",
    "    )\n",
    "\n",
    "    # Call the OpenAI API\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant tasked with extracting and correcting song lyrics from user input and identifying the author if mentioned.\"},\n",
    "            {\"role\": \"user\", \"content\": example_message},\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    # Extract and format the result\n",
    "    output = chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "    # Manually parse the refined query from the output\n",
    "    start_tag = \"<start_refined_query>\"\n",
    "    end_tag = \"<end_refined_query>\"\n",
    "    refined_query = \"\"\n",
    "    if start_tag in output and end_tag in output:\n",
    "        refined_query = output.split(start_tag)[-1].split(end_tag)[0].strip()\n",
    "\n",
    "    print(\"Refined query:\\n\", refined_query)\n",
    "    return refined_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736617333579,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "Hsv8n1c-Nvdg"
   },
   "outputs": [],
   "source": [
    "def song_retrieval_pipeline(query, index, bi_encoder_model='sentence-transformers/all-mpnet-base-v2',\n",
    "                            cross_encoder_model='cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "                            bi_encoder_k=100, cross_encoder_k=10):\n",
    "    # Bi-Encoder\n",
    "    bi_encoder = BiEncoder(bi_encoder_model)\n",
    "\n",
    "    refined_query = refine_query_with_chatgpt(query)\n",
    "    query_embedding = bi_encoder.encode_texts([refined_query])[0].tolist()\n",
    "\n",
    "    # Query Pinecone\n",
    "    results = index.query(vector=query_embedding, top_k=bi_encoder_k, include_metadata=True)\n",
    "\n",
    "    # Initial retrieval with duplicate removal\n",
    "    candidates = []\n",
    "    seen_songs = set()\n",
    "\n",
    "    for match in results[\"matches\"]:\n",
    "        song_key = (match[\"metadata\"][\"Song\"], match[\"metadata\"][\"Artist\"])\n",
    "        if song_key not in seen_songs:\n",
    "            seen_songs.add(song_key)\n",
    "            candidates.append({\n",
    "                \"track_name\": match[\"metadata\"][\"Song\"],\n",
    "                \"artist_name\": match[\"metadata\"][\"Artist\"],\n",
    "                \"lyrics_chunk\": match[\"metadata\"][\"Lyrics\"],\n",
    "                \"score\": match.score\n",
    "            })\n",
    "            if len(candidates) >= bi_encoder_k:  # Stop if we have enough unique songs\n",
    "                break\n",
    "\n",
    "    print(\"Top 10 results before reranking:\")\n",
    "    for candidate in candidates[:10]:\n",
    "        print(f\"Track: {candidate['track_name']}, Artist: {candidate['artist_name']}, Score: {candidate['score']}\")\n",
    "\n",
    "    candidates = sorted(candidates, key=lambda x: x['score'], reverse=True)[:cross_encoder_k]\n",
    "    lyrics_chunks = [candidate[\"lyrics_chunk\"] for candidate in candidates]\n",
    "\n",
    "\n",
    "    from sentence_transformers import CrossEncoder\n",
    "    \n",
    "    # Cross-Encoder\n",
    "    cross_encoder = CrossEncoder(model_name=cross_encoder_model)\n",
    "    candidate_pairs = [(query, chunk) for chunk in lyrics_chunks]\n",
    "    scores = cross_encoder.predict(candidate_pairs, batch_size=16)\n",
    "\n",
    "    # Re-ranking\n",
    "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    re_ranked_songs = [candidates[i] for i in ranked_indices]\n",
    "\n",
    "    print(\"\\nTop 10 results after reranking:\")\n",
    "    for song in re_ranked_songs[:10]:\n",
    "        print(f\"Track: {song['track_name']}, Artist: {song['artist_name']}, Score: {song['score']}\")\n",
    "\n",
    "    return re_ranked_songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3b16be656c7b41e38967e737768c5085",
      "b668bb4e5a84486bbd78f1134533217e",
      "221270ada82a4f2eaf1a9ad387503c6a",
      "1cad04475d1040c28c7dfc37d0c079db",
      "5eb2a27e5b3445238d2a6ae661477196",
      "1703eb1a72164825b76bf20ab17cfba5",
      "3b1bca1828594349a3aaf5f3a646a13b",
      "cc5fe0d38b984954a7c49862d60c65a5",
      "94378d54711941d1bb3e8fc322aa68b7",
      "163c02a5cd9e4b9f8ff25b5cd40c01c2",
      "544d8ad14605452186d7fe8b88fdb278"
     ]
    },
    "executionInfo": {
     "elapsed": 3867,
     "status": "ok",
     "timestamp": 1736617337441,
     "user": {
      "displayName": "Naida Nožić",
      "userId": "16530525352622377711"
     },
     "user_tz": -60
    },
    "id": "eHmwrHLSNvdh",
    "outputId": "d15c7bf6-73b5-4887-ca73-33723d3d6693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined query:\n",
      " Broken heart\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b16be656c7b41e38967e737768c5085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results before reranking:\n",
      "Track: the heart wants what it wants, Artist: selena gomez, Score: 0.464003891\n",
      "Track: damaged, Artist: danity kane, Score: 0.458360195\n",
      "Track: cross my broken heart, Artist: the jets, Score: 0.455789953\n",
      "Track: take a bow, Artist: madonna, Score: 0.44819954\n",
      "Track: second chance, Artist: 38 special, Score: 0.447755396\n",
      "Track: me and my broken heart, Artist: rixton, Score: 0.444622606\n",
      "Track: bad blood, Artist: taylor swift featuring kendrick lamar, Score: 0.429715604\n",
      "Track: bad time, Artist: grand funk, Score: 0.426480383\n",
      "Track: stuck like glue, Artist: sugarland, Score: 0.42581436\n",
      "Track: brokenhearted, Artist: brandy featuring wanya morris, Score: 0.425740361\n",
      "\n",
      "Top 10 results after reranking:\n",
      "Track: cross my broken heart, Artist: the jets, Score: 0.455789953\n",
      "Track: me and my broken heart, Artist: rixton, Score: 0.444622606\n",
      "Track: take a bow, Artist: madonna, Score: 0.44819954\n",
      "Track: brokenhearted, Artist: brandy featuring wanya morris, Score: 0.425740361\n",
      "Track: damaged, Artist: danity kane, Score: 0.458360195\n",
      "Track: the heart wants what it wants, Artist: selena gomez, Score: 0.464003891\n",
      "Track: second chance, Artist: 38 special, Score: 0.447755396\n",
      "Track: stuck like glue, Artist: sugarland, Score: 0.42581436\n",
      "Track: bad blood, Artist: taylor swift featuring kendrick lamar, Score: 0.429715604\n",
      "Track: bad time, Artist: grand funk, Score: 0.426480383\n",
      "Top retrieved songs:\n",
      "1. cross my broken heart by the jets\n",
      "Lyrics Chunk: broken heart boy cross my broken heart for you im going to stay this timecross my broken heart boy\n",
      "\n",
      "2. me and my broken heart by rixton\n",
      "Lyrics Chunk: apart a little but im hoping it might kick start me and my broken heartme and my broken heart me\n",
      "\n",
      "3. take a bow by madonna\n",
      "Lyrics Chunk: where youre breaking my heart breaking my heart hide behind your smile all the world loves a clown\n",
      "\n",
      "4. brokenhearted by brandy featuring wanya morris\n",
      "Lyrics Chunk: start again while im lonely brokenhearted its a hurting thing to get over starting all over\n",
      "\n",
      "5. damaged by danity kane\n",
      "Lyrics Chunk: fix it fix it fix it how you gonna fix it fix it fix itmy heart is damaged damaged damaged my heart\n",
      "\n",
      "6. the heart wants what it wants by selena gomez\n",
      "Lyrics Chunk: feel like its my fault i was in pain intro what the heart wants what the heart wants what the heart\n",
      "\n",
      "7. second chance by 38 special\n",
      "Lyrics Chunk: love makes this sound babe a heart needs a second chancea heart needs a second chance a heart needs\n",
      "\n",
      "8. stuck like glue by sugarland\n",
      "Lyrics Chunk: say its all i wanna do i saidthere you go making my heart beat again heart beat again heart beat\n",
      "\n",
      "9. bad blood by taylor swift featuring kendrick lamar\n",
      "Lyrics Chunk: made a really deep cut and baby now we got bad bloodcause now we got bad blood cause baby now we\n",
      "\n",
      "10. bad time by grand funk\n",
      "Lyrics Chunk: love but i feel like im wearin it out im in love but i must have picked a bad time to be in love a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main program\n",
    "query = \"songs about broken heart\"\n",
    "\n",
    "results = song_retrieval_pipeline(query, index)\n",
    "print(\"Top retrieved songs:\")\n",
    "for idx, song in enumerate(results):\n",
    "    print(f\"{idx + 1}. {song['track_name']} by {song['artist_name']}\")\n",
    "    print(f\"Lyrics Chunk: {song['lyrics_chunk']}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2nshSp8xJIZ"
   },
   "outputs": [],
   "source": [
    "# use this to populate the db IF it is empty\n",
    "def populate_db(dataset_path):\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(\"Dataset not found. Download the dataset to insert it into the db.\")\n",
    "        return\n",
    "\n",
    "    data = load_lyrics_dataset(dataset_path)\n",
    "    preprocess_and_store_embeddings(data, index, chunk_size=100, overlap=50)\n",
    "    print(\"Data saved in db.\")\n",
    "\n",
    "dataset_path = \"dataset.csv\"\n",
    "populate_db(dataset_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "163c02a5cd9e4b9f8ff25b5cd40c01c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1703eb1a72164825b76bf20ab17cfba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cad04475d1040c28c7dfc37d0c079db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_163c02a5cd9e4b9f8ff25b5cd40c01c2",
      "placeholder": "​",
      "style": "IPY_MODEL_544d8ad14605452186d7fe8b88fdb278",
      "value": " 1/1 [00:00&lt;00:00, 18.42it/s]"
     }
    },
    "221270ada82a4f2eaf1a9ad387503c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc5fe0d38b984954a7c49862d60c65a5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94378d54711941d1bb3e8fc322aa68b7",
      "value": 1
     }
    },
    "3b16be656c7b41e38967e737768c5085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b668bb4e5a84486bbd78f1134533217e",
       "IPY_MODEL_221270ada82a4f2eaf1a9ad387503c6a",
       "IPY_MODEL_1cad04475d1040c28c7dfc37d0c079db"
      ],
      "layout": "IPY_MODEL_5eb2a27e5b3445238d2a6ae661477196"
     }
    },
    "3b1bca1828594349a3aaf5f3a646a13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "544d8ad14605452186d7fe8b88fdb278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eb2a27e5b3445238d2a6ae661477196": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94378d54711941d1bb3e8fc322aa68b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b668bb4e5a84486bbd78f1134533217e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1703eb1a72164825b76bf20ab17cfba5",
      "placeholder": "​",
      "style": "IPY_MODEL_3b1bca1828594349a3aaf5f3a646a13b",
      "value": "Batches: 100%"
     }
    },
    "cc5fe0d38b984954a7c49862d60c65a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
