{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12b06b-18eb-41b8-ac8b-4c742f40bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install datasets\n",
    "!pip install sentence_transformers\n",
    "!pip install transformers[torch]\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a4f3fb-26b6-489e-a67c-1173ce9dc088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1YmdITHIV6BNwVQOEN-dHF8dBwO_CKCF5\n",
      "From (redirected): https://drive.google.com/uc?id=1YmdITHIV6BNwVQOEN-dHF8dBwO_CKCF5&confirm=t&uuid=4201e367-06cd-4845-b67b-18318b746b62\n",
      "To: /workspace/output_dataset.csv\n",
      "100%|██████████| 687M/687M [00:06<00:00, 103MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded as: output_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Replace the URL below with your Google Drive shareable link\n",
    "drive_url = \"https://drive.google.com/uc?id=1YmdITHIV6BNwVQOEN-dHF8dBwO_CKCF5\"\n",
    "\n",
    "# Replace 'dataset.csv' with your desired filename\n",
    "output_file = \"output_dataset.csv\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(drive_url, output_file, quiet=False)\n",
    "\n",
    "print(f\"File downloaded as: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8920eac1-d887-4c37-a9bb-e0fcbc6579e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sentence_transformers import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def finetune_embedding_model_v3(\n",
    "    dataset_path,\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    output_model_path=\"fine-tuned-embedding-model-v3\",\n",
    "    batch_size=32,\n",
    "    epochs=3,\n",
    "    learning_rate=1e-5\n",
    "):\n",
    "    \"\"\"\n",
    "    Fine-tunes a pre-trained embedding model using a dataset of query and lyric pairs\n",
    "    (with a numeric 'label' column). Follows the Sentence Transformers v3 approach.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset CSV containing query, full_lyrics, and label.\n",
    "        model_name (str): Name of the pre-trained Sentence Transformers model to finetune.\n",
    "        output_model_path (str): Directory where the fine-tuned model will be saved.\n",
    "        batch_size (int): Batch size for training.\n",
    "        epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        None. Saves the fine-tuned model to the specified output path.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. Load & preprocess data\n",
    "    # -------------------------\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    # Ensure columns exist\n",
    "    required_columns = [\"query\", \"full_lyrics\", \"label\"]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    # Convert label to float if necessary\n",
    "    df[\"label\"] = df[\"label\"].astype(float)\n",
    "    df = df.sample(n=40000, random_state=42)\n",
    "\n",
    "    # Split into train/dev\n",
    "    train_df, eval_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "    train_df = train_df.dropna(subset=[\"query\", \"full_lyrics\", \"label\"])\n",
    "    eval_df = eval_df.dropna(subset=[\"query\", \"full_lyrics\", \"label\"])\n",
    "\n",
    "    # Convert pandas DFs to huggingface Dataset objects.\n",
    "    # We want them in the format:  (text1, text2, label)\n",
    "    # where text1= \"query\", text2=\"full_lyrics\", label=\"label\"\n",
    "    train_dataset = Dataset.from_pandas(train_df[[\"query\", \"full_lyrics\", \"label\"]])\n",
    "    eval_dataset = Dataset.from_pandas(eval_df[[\"query\", \"full_lyrics\", \"label\"]])\n",
    "    train_dataset = train_dataset.remove_columns([\"__index_level_0__\"])\n",
    "    eval_dataset = eval_dataset.remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "    print(train_dataset)\n",
    "    print(eval_dataset)\n",
    "\n",
    "    # ---------------\n",
    "    # 2. Load a model\n",
    "    # ---------------\n",
    "    # This is your base pretrained model that you'll be fine-tuning\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # -----------------\n",
    "    # 3. Define a loss\n",
    "    # -----------------\n",
    "    # CosineSimilarityLoss expects (text1, text2, label) where label is a float similarity score\n",
    "    loss = CosineSimilarityLoss(model)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 4. (Optional) Create an evaluator\n",
    "    # ----------------------------------\n",
    "    # If your labels are 0/1 or some floating scale, an EmbeddingSimilarityEvaluator can help track the model’s\n",
    "    # performance on the dev set. Just ensure your labels make sense as a \"similarity\" measure.\n",
    "    # For binary 0/1, you can still treat 1 => \"similar\" and 0 => \"not similar\", but\n",
    "    # be aware that you'll get typical correlation metrics, etc.\n",
    "    dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=eval_dataset[\"query\"],\n",
    "        sentences2=eval_dataset[\"full_lyrics\"],\n",
    "        scores=eval_dataset[\"label\"],\n",
    "        main_similarity=SimilarityFunction.COSINE,\n",
    "        name=\"my-dev-set\",\n",
    "    )\n",
    "    dev_evaluator(model)\n",
    "    # You can run dev_evaluator(model) manually if you’d like a baseline before training.\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 5. Specify training arguments and trainer\n",
    "    # -----------------------------------------\n",
    "    training_args = SentenceTransformerTrainingArguments(\n",
    "        output_dir=output_model_path,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        # Optional but useful\n",
    "        eval_strategy=\"steps\",      # Evaluate every N steps\n",
    "        eval_steps=225,                  # How often to run dev_evaluator\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=225,\n",
    "        warmup_steps=337,\n",
    "        save_total_limit=2,\n",
    "        logging_steps=100,\n",
    "        fp16=True,  # Set to False if your GPU doesn’t support FP16\n",
    "        # run_name=\"my-st-v3-run\"  # If you have W&B or another logging tool\n",
    "    )\n",
    "\n",
    "    # Create the trainer\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,   # For eval loss\n",
    "        loss=loss,\n",
    "        evaluator=dev_evaluator,     # For additional metrics\n",
    "    )\n",
    "\n",
    "    # -----------------\n",
    "    # 6. Train the model\n",
    "    # -----------------\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    total_steps = (len(train_dataset) // batch_size) * epochs\n",
    "    progress_bar = tqdm(total=total_steps, desc=\"Training Progress\")\n",
    "\n",
    "    # If you want to manually loop over epochs:\n",
    "    for epoch in range(epochs):\n",
    "        trainer.train()  # This runs one full epoch by default\n",
    "        progress_bar.update(len(train_dataset) // batch_size)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Alternatively (and more simply):\n",
    "    # trainer.train()   # would do all epochs automatically, but you'd lose the custom progress_bar above\n",
    "\n",
    "    # -------------------------\n",
    "    # 7. Evaluate final metrics\n",
    "    # -------------------------\n",
    "    if dev_evaluator is not None:\n",
    "        print(\"Final evaluation on dev set:\")\n",
    "        print(dev_evaluator(model))\n",
    "\n",
    "    # ---------------------------\n",
    "    # 8. Save the fine-tuned model\n",
    "    # ---------------------------\n",
    "    model.save_pretrained(output_model_path)\n",
    "    print(f\"Model fine-tuned and saved to {output_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc84a3d2-fde6-4010-99bb-0bb6c90e601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query', 'full_lyrics', 'label'],\n",
      "    num_rows: 35892\n",
      "})\n",
      "Dataset({\n",
      "    features: ['query', 'full_lyrics', 'label'],\n",
      "    num_rows: 3992\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:   0%|          | 0/3363 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3366' max='3366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3366/3366 24:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>My-dev-set Pearson Cosine</th>\n",
       "      <th>My-dev-set Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.058240</td>\n",
       "      <td>0.479995</td>\n",
       "      <td>0.369713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.052005</td>\n",
       "      <td>0.516648</td>\n",
       "      <td>0.344231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.051278</td>\n",
       "      <td>0.559059</td>\n",
       "      <td>0.359910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>0.562503</td>\n",
       "      <td>0.359318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.049428</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.367651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>0.574608</td>\n",
       "      <td>0.360213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.047949</td>\n",
       "      <td>0.574154</td>\n",
       "      <td>0.355734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.348593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.047472</td>\n",
       "      <td>0.566560</td>\n",
       "      <td>0.355099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.047465</td>\n",
       "      <td>0.585280</td>\n",
       "      <td>0.361725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.047686</td>\n",
       "      <td>0.570788</td>\n",
       "      <td>0.353236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.577073</td>\n",
       "      <td>0.356237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.047345</td>\n",
       "      <td>0.576868</td>\n",
       "      <td>0.352563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.048175</td>\n",
       "      <td>0.574192</td>\n",
       "      <td>0.354041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:  33%|███▎      | 1121/3363 [24:48<49:36,  1.33s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3366' max='3366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3366/3366 24:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>My-dev-set Pearson Cosine</th>\n",
       "      <th>My-dev-set Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.048230</td>\n",
       "      <td>0.550775</td>\n",
       "      <td>0.342356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.048285</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.336176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.052202</td>\n",
       "      <td>0.551306</td>\n",
       "      <td>0.336336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.549791</td>\n",
       "      <td>0.334867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.047905</td>\n",
       "      <td>0.574196</td>\n",
       "      <td>0.348126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.047115</td>\n",
       "      <td>0.558874</td>\n",
       "      <td>0.334133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.051110</td>\n",
       "      <td>0.538228</td>\n",
       "      <td>0.330184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.048626</td>\n",
       "      <td>0.542434</td>\n",
       "      <td>0.327884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>0.551660</td>\n",
       "      <td>0.337767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.048656</td>\n",
       "      <td>0.557036</td>\n",
       "      <td>0.337676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.048992</td>\n",
       "      <td>0.547948</td>\n",
       "      <td>0.331108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.050398</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.048538</td>\n",
       "      <td>0.550152</td>\n",
       "      <td>0.332003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.049095</td>\n",
       "      <td>0.549219</td>\n",
       "      <td>0.332023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:  67%|██████▋   | 2242/3363 [49:37<24:48,  1.33s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3366' max='3366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3366/3366 24:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>My-dev-set Pearson Cosine</th>\n",
       "      <th>My-dev-set Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.547050</td>\n",
       "      <td>0.327964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.050662</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>0.327927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.055982</td>\n",
       "      <td>0.519462</td>\n",
       "      <td>0.318151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.048238</td>\n",
       "      <td>0.526264</td>\n",
       "      <td>0.314759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.050834</td>\n",
       "      <td>0.547683</td>\n",
       "      <td>0.329524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.048799</td>\n",
       "      <td>0.529846</td>\n",
       "      <td>0.318289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.052959</td>\n",
       "      <td>0.523394</td>\n",
       "      <td>0.318562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.049630</td>\n",
       "      <td>0.529122</td>\n",
       "      <td>0.318791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.048937</td>\n",
       "      <td>0.534860</td>\n",
       "      <td>0.320914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.050623</td>\n",
       "      <td>0.530334</td>\n",
       "      <td>0.320643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.050346</td>\n",
       "      <td>0.522655</td>\n",
       "      <td>0.317543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.050913</td>\n",
       "      <td>0.529632</td>\n",
       "      <td>0.320852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.050850</td>\n",
       "      <td>0.530315</td>\n",
       "      <td>0.321020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.050466</td>\n",
       "      <td>0.532711</td>\n",
       "      <td>0.319974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress: 100%|██████████| 3363/3363 [1:14:28<00:00,  1.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on dev set:\n",
      "{'my-dev-set_pearson_cosine': 0.5330700861787097, 'my-dev-set_spearman_cosine': 0.3202504036973425}\n",
      "Model fine-tuned and saved to fine-tuned-embedding-model-v3\n"
     ]
    }
   ],
   "source": [
    "finetune_embedding_model_v3(\n",
    "    dataset_path = \"output_dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17e6f2-b728-4156-acdd-3e3e2a8915b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
